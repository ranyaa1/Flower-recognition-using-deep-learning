{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "authorship_tag": "ABX9TyN/o2lKoR92eOlpf6ij4Uh7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ranyaa1/Flower-recognition-using-deep-learning/blob/main/softavera.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install psycopg2"
      ],
      "metadata": {
        "id": "60zHY_xnRMGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy"
      ],
      "metadata": {
        "id": "nr6nv4cfRSbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67XSeu4xKrcU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy  as np\n",
        "import psycopg2\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from kneed import KneeLocator\n",
        "import skfuzzy as fuzz\n",
        "from sklearn.metrics import silhouette_score # Importing the silhouette_score function from sklearn.metrics\n",
        "from sklearn.metrics import davies_bouldin_score\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import psycopg2\n",
        "import pandas as pd\n",
        "\n",
        "# Connexion à la base PostgreSQL\n",
        "conn = psycopg2.connect(\n",
        "    dbname=\"postgres\",         # ou le vrai nom de ta base\n",
        "    user=\"postgres\",\n",
        "    password=\"1234\",\n",
        "    host=\"localhost\",          # ou l’IP de ton serveur\n",
        "    port=\"5432\"\n",
        ")\n",
        "\n",
        "# Créer un curseur\n",
        "cur = conn.cursor()\n",
        "\n",
        "# Requête SQL\n",
        "query = \"SELECT * FROM frch_stage.client_boutique;\"\n",
        "\n",
        "# Lire les résultats dans un DataFrame pandas\n",
        "df = pd.read_sql_query(query, conn)\n",
        "\n",
        "# Afficher les premières lignes\n",
        "print(df.head())\n",
        "\n",
        "# Fermer la connexion\n",
        "cur.close()\n",
        "conn.close()\n"
      ],
      "metadata": {
        "id": "gLSP97SbvUR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ojP9xdZr36BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory data analysis**"
      ],
      "metadata": {
        "id": "je9GxuLYsP-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing values**"
      ],
      "metadata": {
        "id": "5C_VXYaxsZnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RFM Table Preparation**"
      ],
      "metadata": {
        "id": "PgfDcj-lG7NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ----------- Calcul du RFM -----------\n",
        "# Convertir 'last_order' en datetime\n",
        "df['last_order'] = pd.to_datetime(df['last_order'], errors='coerce')\n",
        "\n",
        "# Obtenir la date actuelle et la date limite des 10 dernières années\n",
        "now = pd.to_datetime('today').date()\n",
        "ten_years_ago = now.replace(year=now.year - 10)  # Date limite il y a 10 ans\n",
        "\n",
        "# Filtrer les données des 10 dernières années\n",
        "df_filtered = df[df['last_order'].dt.date >= ten_years_ago]\n",
        "\n",
        "# Calculer la récence (R)\n",
        "recency = df_filtered.groupby('id_client')['last_order'].max().reset_index()\n",
        "recency['LastPurchaseDate'] = recency['last_order'].dt.date\n",
        "recency['Recency'] = (now - recency['LastPurchaseDate']).apply(lambda x: x.days)\n",
        "\n",
        "# Calculer la fréquence (F) et le montant total (M)\n",
        "frequency = df_filtered.groupby('id_client')['total_order'].sum().reset_index()\n",
        "monetary = df_filtered.groupby('id_client')['revenue'].sum().reset_index()\n",
        "\n",
        "# Fusionner les résultats pour obtenir le tableau RFM\n",
        "rfm_df = recency[['id_client', 'Recency']].merge(frequency, on='id_client').merge(monetary, on='id_client')\n",
        "\n",
        "# Renommer les colonnes\n",
        "rfm_df.rename(columns={'Recency': 'Recency',\n",
        "                       'total_order': 'Frequency',\n",
        "                       'revenue': 'Monetary'},\n",
        "              inplace=True)\n",
        "\n",
        "# Afficher les 5 premières lignes\n",
        "print(rfm_df.head())"
      ],
      "metadata": {
        "id": "_rAjD3kvKDos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cellule 1: Boxplot et Distplot pour Recency\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Boxplot pour Recency\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=rfm_df['Recency'])\n",
        "plt.title('Boxplot de la Récence')\n",
        "\n",
        "# Distplot pour Recency\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(rfm_df['Recency'], kde=True)\n",
        "plt.title('Distribution de la Récence')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HOaa8A6pKLI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cellule 2: Boxplot et Distplot pour Frequency\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Boxplot pour Frequency\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=rfm_df['Frequency'])\n",
        "plt.title('Boxplot de la Fréquence')\n",
        "\n",
        "# Distplot pour Frequency\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(rfm_df['Frequency'], kde=True)\n",
        "plt.title('Distribution de la Fréquence')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HqDWDtq0KtmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cellule 3: Boxplot et Distplot pour Monetary\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Boxplot pour Monetary\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=rfm_df['Monetary'])\n",
        "plt.title('Boxplot du Montant')\n",
        "\n",
        "# Distplot pour Monetary\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(rfm_df['Monetary'], kde=True)\n",
        "plt.title('Distribution du Montant')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pDn6G__dKy2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Étape 1 : Calcul des bornes IQR\n",
        "Q1 = rfm_df['Frequency'].quantile(0.25)\n",
        "Q3 = rfm_df['Frequency'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Étape 2 : Remplacement des outliers par la moyenne\n",
        "mean_value = rfm_df['Frequency'].mean()\n",
        "rfm_df['Frequency_corrected'] = rfm_df['Frequency'].apply(\n",
        "    lambda x: mean_value if x < lower_bound or x > upper_bound else x\n",
        ")\n",
        "\n",
        "# Étape 3 : Affichage des boxplot et distplot\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Boxplot\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=rfm_df['Frequency_corrected'])\n",
        "plt.title('Boxplot corrigé de la Fréquence (mean)')\n",
        "\n",
        "# Distplot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(rfm_df['Frequency_corrected'], kde=True)\n",
        "plt.title('Distribution corrigée de la Fréquence (mean)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S936kS3QK47J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Étape 1 : Calcul des bornes IQR pour Monetary\n",
        "Q1_m = rfm_df['Monetary'].quantile(0.25)\n",
        "Q3_m = rfm_df['Monetary'].quantile(0.75)\n",
        "IQR_m = Q3_m - Q1_m\n",
        "lower_bound_m = Q1_m - 1.5 * IQR_m\n",
        "upper_bound_m = Q3_m + 1.5 * IQR_m\n",
        "\n",
        "# Étape 2 : Appliquer le capping/flooring\n",
        "rfm_df['Monetary_capped'] = rfm_df['Monetary'].apply(\n",
        "    lambda x: lower_bound_m if x < lower_bound_m else upper_bound_m if x > upper_bound_m else x\n",
        ")\n",
        "\n",
        "# Étape 3 : Affichage boxplot + distplot\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "# Boxplot\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.boxplot(y=rfm_df['Monetary_capped'])\n",
        "plt.title('Boxplot - Monetary (Capping/Flooring)')\n",
        "\n",
        "# Distplot\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(rfm_df['Monetary_capped'], kde=True)\n",
        "plt.title('Distribution - Monetary (Capping/Flooring)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7u8AmPi-K-lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(rfm_df.corr(), annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "\n",
        "plt.title('Heatmap of Correlation Matrix for RFM Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PSn-sEW1CMK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# plot the distribution of RFM values\n",
        "f,ax = plt.subplots(figsize=(15, 15))\n",
        "plt.subplot(3, 1, 1); sns.distplot(rfm_df.Recency, label = 'Recency')\n",
        "plt.subplot(3, 1, 2); sns.distplot(rfm_df.Frequency, label = 'Frequency')\n",
        "plt.subplot(3, 1, 3); sns.distplot(rfm_df.Monetary, label = 'Monetary')\n",
        "plt.style.use('fivethirtyeight')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yf6RWMFqtlT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Features engineering**"
      ],
      "metadata": {
        "id": "7QNpeexLs5WV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Transformation**"
      ],
      "metadata": {
        "id": "qPSu8PoztQiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df"
      ],
      "metadata": {
        "id": "xHUT_fy7fFZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kneed"
      ],
      "metadata": {
        "id": "uzhaq7Bckdhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ignorer les warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Standardisation\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled = scaler.fit_transform(rfm_df)"
      ],
      "metadata": {
        "id": "_bE91lB32SV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature extraction\n"
      ],
      "metadata": {
        "id": "gnVVP-gR2WRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# PCA à 2 dimensions\n",
        "pca = PCA(n_components=2)\n",
        "rfm_pca = pca.fit_transform(rfm_scaled)\n",
        "rfm_pca_df = pd.DataFrame(rfm_pca, columns=['PCA1', 'PCA2'])\n"
      ],
      "metadata": {
        "id": "ZHxc1rIH2iz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "kmean"
      ],
      "metadata": {
        "id": "LZrhm4Ac2leY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calcule de WCSS\n",
        "wcss = []\n",
        "for i in range(1, 11):\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
        "    kmeans.fit(rfm_pca_df)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "# Trouver l'optimal cluster avec KneeLocator\n",
        "kl = KneeLocator(range(1, 11), wcss, curve='convex', direction='decreasing')\n",
        "elbow_point = kl.elbow\n",
        "\n",
        "# Tracer la courbe du coude\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 11), wcss, marker='o', linestyle='-', color='b', label='WCSS')\n",
        "plt.axvline(x=elbow_point, color='red', linestyle='--', label=f'Elbow = {elbow_point}')\n",
        "plt.scatter(elbow_point, wcss[elbow_point-1], color='red', s=100)\n",
        "plt.title('Elbow Method with Optimal Cluster')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Within-Cluster Sum of Squares (WCSS)')\n",
        "plt.xticks(range(1, 11))\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xo6On5PqwlxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Silhouette Score pour chaque k\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "print(\"Silhouette Scores by number of clusters:\")\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
        "    kmeans.fit(rfm_pca_df)\n",
        "    labels = kmeans.labels_\n",
        "    score = silhouette_score(rfm_pca_df, labels)\n",
        "    silhouette_scores.append(score)\n",
        "    print(f\"k = {k}: Silhouette Score = {score:.4f}\")\n",
        "\n",
        "# Tracer le graphique\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, silhouette_scores, marker='o', linestyle='-', color='green')\n",
        "plt.title('Silhouette Score vs Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "eQnuCVpYftsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Listes pour stocker les scores\n",
        "silhouette_scores = []\n",
        "db_scores = []\n",
        "\n",
        "# Plage des valeurs de k à tester\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(rfm_pca_df)\n",
        "    labels = kmeans.labels_\n",
        "\n",
        "    silhouette = silhouette_score(rfm_pca_df, labels)\n",
        "    db = davies_bouldin_score(rfm_pca_df, labels)\n",
        "\n",
        "    silhouette_scores.append(silhouette)\n",
        "    db_scores.append(db)\n",
        "\n",
        "# Tracer les deux scores sur le même graphique\n",
        "sns.set(style=\"whitegrid\")\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Axe pour Silhouette Score\n",
        "color = 'tab:green'\n",
        "ax1.set_xlabel('Nombre de clusters (k)')\n",
        "ax1.set_ylabel('Silhouette Score', color=color)\n",
        "ax1.plot(K_range, silhouette_scores, marker='o', color=color, label='Silhouette Score')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# Deuxième axe y pour Davies-Bouldin Score\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:red'\n",
        "ax2.set_ylabel('Davies-Bouldin Score', color=color)\n",
        "ax2.plot(K_range, db_scores, marker='s', color=color, label='Davies-Bouldin Score')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# Titre et affichage\n",
        "plt.title('Comparaison des scores Silhouette et Davies-Bouldin selon k')\n",
        "plt.xticks(K_range)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "KM8HbvC_LGUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Afficher les scores\n",
        "print(\"Scores pour chaque valeur de k:\")\n",
        "print(f\"{'k':<5}{'Silhouette Score':<25}{'Davies-Bouldin Score'}\")\n",
        "for k, sil, db in zip(K_range, silhouette_scores, db_scores):\n",
        "    print(f\"{k:<5}{sil:<25.4f}{db:.4f}\")"
      ],
      "metadata": {
        "id": "dpE82Ei617m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyclustering\n"
      ],
      "metadata": {
        "id": "vq0a7UmgH0WW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sklearn-extra pyclustering scikit-fuzzy\n"
      ],
      "metadata": {
        "id": "XQ3qGAHeLbvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fuzzy C-Means"
      ],
      "metadata": {
        "id": "jSWdQ9w23TUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import skfuzzy as fuzz\n",
        "\n",
        "# List to store inertia values\n",
        "inertia_scores_fcm = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "# Calculate Fuzzy C-Means and inertia\n",
        "for k in k_range:\n",
        "    # Apply Fuzzy C-Means\n",
        "    cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(rfm_pca_df.values.T, k, 2, error=1e-5, maxiter=1000)\n",
        "\n",
        "    # Compute inertia for Fuzzy C-Means (sum of squared distances to the cluster centers)\n",
        "    fcm_labels = np.argmax(u, axis=0)\n",
        "    inertia = np.sum((rfm_pca_df.values - cntr[fcm_labels])**2)\n",
        "\n",
        "    # Store inertia value\n",
        "    inertia_scores_fcm.append(inertia)\n",
        "\n",
        "# Plot the Elbow Method for Fuzzy C-Means (Inertia)\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(k_range, inertia_scores_fcm, marker='o', linestyle='-', color='green', label='Inertia (Fuzzy C-Means)')\n",
        "ax.set_xlabel('Number of Clusters (k)')\n",
        "ax.set_ylabel('Inertia')\n",
        "ax.set_title('Elbow Method for Fuzzy C-Means')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RrooBa7ZQ_dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "silhouette_scores_fcm = []\n",
        "db_scores_fcm = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "print(f\"{'k':<5}{'Silhouette Score':<25}{'Davies-Bouldin Score'}\")\n",
        "for k in k_range:\n",
        "    # Appliquer Fuzzy C-Means\n",
        "    cntr, u, _, _, _, _, _ = fuzz.cluster.cmeans(rfm_pca_df.values.T, k, 2, error=1e-5, maxiter=1000)\n",
        "\n",
        "    fcm_labels = np.argmax(u, axis=0)\n",
        "\n",
        "    sil_score = silhouette_score(rfm_pca_df, fcm_labels)\n",
        "    db_score = davies_bouldin_score(rfm_pca_df, fcm_labels)\n",
        "\n",
        "    silhouette_scores_fcm.append(sil_score)\n",
        "    db_scores_fcm.append(db_score)\n",
        "\n",
        "    print(f\"{k:<5}{sil_score:<25.4f}{db_score:.4f}\")\n",
        "\n",
        "# Tracer les courbes\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Axe pour Silhouette Score\n",
        "color = 'blue'\n",
        "ax1.set_xlabel('Nombre de clusters (k)')\n",
        "ax1.set_ylabel('Silhouette Score', color=color)\n",
        "ax1.plot(k_range, silhouette_scores_fcm, marker='o', linestyle='-', color=color, label='Silhouette Score')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "# Deuxième axe y pour Davies-Bouldin Score\n",
        "ax2 = ax1.twinx()\n",
        "color = 'red'\n",
        "ax2.set_ylabel('Davies-Bouldin Score', color=color)\n",
        "ax2.plot(k_range, db_scores_fcm, marker='s', linestyle='--', color=color, label='Davies-Bouldin Score')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Fuzzy C-Means: Silhouette vs Davies-Bouldin Scores')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3M18An1vhpYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Shift"
      ],
      "metadata": {
        "id": "pT57D0NL39e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MeanShift # Import MeanShift\n",
        "\n",
        "meanshift = MeanShift()\n",
        "labels_meanshift = meanshift.fit_predict(rfm_pca_df)\n",
        "\n",
        "# Calcul des scores\n",
        "silhouette_avg = silhouette_score(rfm_pca_df, labels_meanshift)\n",
        "db_score = davies_bouldin_score(rfm_pca_df, labels_meanshift)\n",
        "\n",
        "# Affichage des scores\n",
        "print(f\"Mean Shift Clustering Results:\")\n",
        "print(f\"- Silhouette Score         : {silhouette_avg:.4f}\")\n",
        "print(f\"- Davies-Bouldin Score     : {db_score:.4f}\")\n",
        "print(f\"- Nombre de clusters trouvés : {len(set(labels_meanshift))}\")\n",
        "\n",
        "# Visualisation\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(rfm_pca_df['PCA1'], rfm_pca_df['PCA2'], c=labels_meanshift, cmap='viridis', s=50)\n",
        "plt.title(\"Mean Shift Clustering\")\n",
        "plt.xlabel(\"PCA1\")\n",
        "plt.ylabel(\"PCA2\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "duWYZVADi00Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sil_scores = []\n",
        "db_scores = []\n",
        "n_range = range(2, 11)\n",
        "\n",
        "print(\"Scores pour GMM (Gaussian Mixture Model):\")\n",
        "for n in n_range:\n",
        "    gmm = GaussianMixture(n_components=n, random_state=42)\n",
        "    labels = gmm.fit_predict(rfm_pca_df)\n",
        "\n",
        "    sil = silhouette_score(rfm_pca_df, labels)\n",
        "    db = davies_bouldin_score(rfm_pca_df, labels)\n",
        "\n",
        "    sil_scores.append(sil)\n",
        "    db_scores.append(db)\n",
        "\n",
        "    print(f\"n_components = {n}: Silhouette = {sil:.4f}, Davies-Bouldin = {db:.4f}\")\n",
        "\n",
        "# Visualisation\n",
        "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "# Axe gauche : Silhouette Score\n",
        "color = 'tab:blue'\n",
        "ax1.set_xlabel('Number of Components')\n",
        "ax1.set_ylabel('Silhouette Score', color=color)\n",
        "ax1.plot(n_range, sil_scores, marker='o', color=color, label='Silhouette Score')\n",
        "ax1.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "color = 'tab:orange'\n",
        "ax2.set_ylabel('Davies-Bouldin Score', color=color)\n",
        "ax2.plot(n_range, db_scores, marker='s', color=color, label='Davies-Bouldin Score')\n",
        "ax2.tick_params(axis='y', labelcolor=color)\n",
        "\n",
        "plt.title('Silhouette vs Davies-Bouldin Scores (GMM)')\n",
        "plt.grid(True)\n",
        "plt.xticks(n_range)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dVDMCp0QjRCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Tester plusieurs valeurs de k\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)\n",
        "\n",
        "print(\"Silhouette Scores (Spectral Clustering):\")\n",
        "for k in k_range:\n",
        "    spectral = SpectralClustering(n_clusters=k, affinity='nearest_neighbors', random_state=42)\n",
        "    labels = spectral.fit_predict(rfm_pca_df)\n",
        "    score = silhouette_score(rfm_pca_df, labels)\n",
        "    silhouette_scores.append(score)\n",
        "    print(f\"k = {k}: Silhouette Score = {score:.4f}\")\n",
        "\n",
        "# Tracer la courbe\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, silhouette_scores, marker='o', linestyle='-', color='purple')\n",
        "plt.title('Silhouette Score vs Number of Clusters (Spectral Clustering)')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1IMVgYhwnGlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-learn-extra\n"
      ],
      "metadata": {
        "id": "WoPwOvHK-0xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade numpy"
      ],
      "metadata": {
        "id": "gMbfzM5C--XZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall sklearn-extra"
      ],
      "metadata": {
        "id": "xB-4TMkx_AAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall scikit-learn"
      ],
      "metadata": {
        "id": "sJZ-bfKb_Bl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4\n",
        "!pip install --upgrade --force-reinstall scikit-learn-extra\n"
      ],
      "metadata": {
        "id": "_IX8WxLB_yV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn_extra.cluster import KMedoids\n",
        "from kneed import KneeLocator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Liste pour stocker la \"pseudo-inertia\" (somme des distances intra-cluster)\n",
        "inertia_kmedoids = []\n",
        "k_range = range(1, 11)\n",
        "\n",
        "for k in k_range:\n",
        "    kmedoids = KMedoids(n_clusters=k, random_state=42, method='pam')\n",
        "    kmedoids.fit(rfm_pca_df)\n",
        "\n",
        "    # Calcule la somme des distances intra-cluster (médiane -> points affectés)\n",
        "    total_distance = 0\n",
        "    for i in range(k):\n",
        "        cluster_points = rfm_pca_df[kmedoids.labels_ == i]\n",
        "        medoid = kmedoids.cluster_centers_[i]\n",
        "        total_distance += np.sum(np.linalg.norm(cluster_points - medoid, axis=1))\n",
        "\n",
        "    inertia_kmedoids.append(total_distance)\n",
        ",\n",
        "# Trouver le coude\n",
        "kl = KneeLocator(k_range, inertia_kmedoids, curve='convex', direction='decreasing')\n",
        "elbow_k = kl.elbow\n",
        "\n",
        "# Tracer la courbe du coude\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, inertia_kmedoids, marker='o', linestyle='-', color='purple', label='Total Intra-Cluster Distance')\n",
        "if elbow_k is not None:\n",
        "    plt.axvline(x=elbow_k, color='red', linestyle='--', label=f'Elbow = {elbow_k}')\n",
        "    plt.scatter(elbow_k, inertia_kmedoids[elbow_k - 1], color='red', s=100)\n",
        "plt.title('Elbow Method for K-Medoids (Pseudo-Inertia)')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Total Intra-Cluster Distance')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v_WzvleY-37E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Appliquer KMeans pour k=2\n",
        "kmeans_2 = KMeans(n_clusters=2, init='random', random_state=42)\n",
        "clusters_2 = kmeans_2.fit_predict(rfm_pca_df)\n",
        "silhouette_2 = silhouette_score(rfm_pca_df, clusters_2)\n",
        "\n",
        "# Appliquer KMeans pour k=3\n",
        "kmeans_3 = KMeans(n_clusters=3, init='random', random_state=42)\n",
        "clusters_3 = kmeans_3.fit_predict(rfm_pca_df)\n",
        "silhouette_3 = silhouette_score(rfm_pca_df, clusters_3)\n",
        "\n",
        "# Créer deux subplots côte à côte\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Visualisation pour k=2\n",
        "ax1.scatter(rfm_pca_df['PCA1'], rfm_pca_df['PCA2'], c=clusters_2, cmap='Set2', s=50)\n",
        "ax1.set_title(f'Clusters (k=2)\\nSilhouette = {silhouette_2:.3f}')\n",
        "ax1.set_xlabel('PCA1')\n",
        "ax1.set_ylabel('PCA2')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Visualisation pour k=3\n",
        "ax2.scatter(rfm_pca_df['PCA1'], rfm_pca_df['PCA2'], c=clusters_3, cmap='Set1', s=50)\n",
        "ax2.set_title(f'Clusters (k=3)\\nSilhouette = {silhouette_3:.3f}')\n",
        "ax2.set_xlabel('PCA1')\n",
        "ax2.set_ylabel('PCA2')\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.suptitle('Comparaison des clusters avec PCA (k=2 vs k=3)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "JA5Lg8tyk89M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled = scaler.fit_transform(rfm_df)\n",
        "\n",
        "# Architecture de l'autoencoder améliorée\n",
        "input_dim = rfm_scaled.shape[1]\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "x = Dense(64, activation='relu')(input_layer)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "bottleneck = Dense(2, activation='tanh')(x)\n",
        "x = Dense(32, activation='relu')(bottleneck)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output_layer = Dense(input_dim, activation='linear')(x)\n",
        "\n",
        "# Modèle Autoencoder\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "autoencoder.fit(rfm_scaled, rfm_scaled, epochs=100, batch_size=32, shuffle=True, verbose=1)\n",
        "\n",
        "# Obtenir l'espace latent\n",
        "rfm_autoencoded = encoder.predict(rfm_scaled)\n",
        "\n",
        "# Clustering avec KMeans\n",
        "kmeans_2 = KMeans(n_clusters=2, init='random', random_state=42)\n",
        "clusters_2 = kmeans_2.fit_predict(rfm_autoencoded)\n",
        "\n",
        "kmeans_3 = KMeans(n_clusters=3, init='random', random_state=42)\n",
        "clusters_3 = kmeans_3.fit_predict(rfm_autoencoded)\n",
        "\n",
        "# Silhouette scores\n",
        "score_k2 = silhouette_score(rfm_autoencoded, clusters_2)\n",
        "score_k3 = silhouette_score(rfm_autoencoded, clusters_3)\n",
        "print(\"Silhouette score (Autoencoder + k=2):\", round(score_k2, 3))\n",
        "print(\"Silhouette score (Autoencoder + k=3):\", round(score_k3, 3))\n",
        "\n",
        "# Visualisation avec seaborn\n",
        "df_latent = pd.DataFrame(rfm_autoencoded, columns=['Latent 1', 'Latent 2'])\n",
        "df_latent['Cluster_k2'] = clusters_2\n",
        "df_latent['Cluster_k3'] = clusters_3\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "sns.scatterplot(data=df_latent, x='Latent 1', y='Latent 2', hue='Cluster_k2', palette='Set2', s=60, ax=axes[0])\n",
        "axes[0].set_title('Clusters avec Autoencoder (k=2)')\n",
        "axes[0].grid(True)\n",
        "\n",
        "sns.scatterplot(data=df_latent, x='Latent 1', y='Latent 2', hue='Cluster_k3', palette='Set1', s=60, ax=axes[1])\n",
        "axes[1].set_title('Clusters avec Autoencoder (k=3)')\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.suptitle('Comparaison des clusters Autoencoder (k=2 vs k=3)', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B8BbGjAbqVgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install umap-learn\n"
      ],
      "metadata": {
        "id": "2ma2MSWi4TmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Liste pour stocker les scores\n",
        "silhouette_scores = []\n",
        "\n",
        "# Tester différents nombres de clusters\n",
        "k_range = range(2, 11)\n",
        "\n",
        "print(\"Silhouette Scores (Clustering Hiérarchique) :\")\n",
        "for k in k_range:\n",
        "    hc = AgglomerativeClustering(n_clusters=k)\n",
        "    labels = hc.fit_predict(rfm_pca_df)\n",
        "    score = silhouette_score(rfm_pca_df, labels)\n",
        "    silhouette_scores.append(score)\n",
        "    print(f\"k = {k}: Silhouette Score = {score:.4f}\")\n",
        "\n",
        "# Tracer les scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, silhouette_scores, marker='o', linestyle='-', color='purple')\n",
        "plt.title('Silhouette Score vs Number of Clusters (Hierarchical Clustering)')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.xticks(k_range)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ddtFSFOnFjnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "silhouette_scores = []\n",
        "\n",
        "for n_clusters in range(2, 11):  # Tester les clusters entre 2 et 10\n",
        "    agg_clust = AgglomerativeClustering(n_clusters=n_clusters, linkage='complete')\n",
        "    labels = agg_clust.fit_predict(rfm_pca_df)\n",
        "    silhouette_avg = silhouette_score(rfm_pca_df, labels)\n",
        "    silhouette_scores.append(silhouette_avg)\n",
        "# Afficher les valeurs de silhouette scores pour chaque k\n",
        "for k, score in zip(K_range, silhouette_scores):\n",
        "    print(f\"Pour k = {k}, le score de silhouette est {score:.4f}\")\n",
        "\n",
        "# Afficher les scores de silhouette pour chaque k\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(2, 11), silhouette_scores, marker='o', color='b')\n",
        "plt.title('Scores de Silhouette pour différents nombres de clusters')\n",
        "plt.xlabel('Nombre de Clusters')\n",
        "plt.ylabel('Score de Silhouette')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0j9GViBtPLqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Essayer plusieurs valeurs de k pour GMM\n",
        "silhouette_scores = []\n",
        "k_range = range(2, 11)  # Tester de 2 à 10 clusters\n",
        "\n",
        "for k in k_range:\n",
        "    gmm = GaussianMixture(n_components=k, random_state=42)\n",
        "    gmm_labels = gmm.fit_predict(rfm_pca_df)\n",
        "    score = silhouette_score(rfm_pca_df, gmm_labels)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "# Trouver le k optimal avec le meilleur score de silhouette\n",
        "optimal_k = k_range[silhouette_scores.index(max(silhouette_scores))]\n",
        "print(f\"Le nombre optimal de clusters selon le score de silhouette est : {optimal_k}\")\n"
      ],
      "metadata": {
        "id": "4AJpvb_JVnvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Chargement des données RFM\n",
        "# ----------------------------\n",
        "# Exemple : si tu as déjà ton rfm_df, sinon charge-le\n",
        "# rfm_df = pd.read_csv('chemin/vers/tes_donnees.csv')\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Normalisation des données\n",
        "# ----------------------------\n",
        "scaler = StandardScaler()\n",
        "rfm_scaled = scaler.fit_transform(rfm_df)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Autoencoder\n",
        "# ----------------------------\n",
        "input_dim = rfm_scaled.shape[1]\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "x = Dense(64, activation='relu')(input_layer)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "bottleneck = Dense(2, activation='tanh')(x)\n",
        "x = Dense(32, activation='relu')(bottleneck)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "output_layer = Dense(input_dim, activation='linear')(x)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "encoder = Model(inputs=input_layer, outputs=bottleneck)\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "autoencoder.fit(rfm_scaled, rfm_scaled, epochs=100, batch_size=32, shuffle=True, verbose=1)\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Réduction dimensionnelle\n",
        "# ----------------------------\n",
        "rfm_autoencoded = encoder.predict(rfm_scaled)\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Clustering avec KMeans (k=3)\n",
        "# ----------------------------\n",
        "kmeans = KMeans(n_clusters=3, init='random', random_state=42)\n",
        "clusters = kmeans.fit_predict(rfm_autoencoded)\n",
        "\n",
        "# Ajouter les clusters à la DataFrame d'origine\n",
        "rfm_df['Cluster'] = clusters\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Silhouette Score\n",
        "# ----------------------------\n",
        "sil_score = silhouette_score(rfm_autoencoded, clusters)\n",
        "print(f\"Silhouette Score pour k=3 : {round(sil_score, 4)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Visualisation des clusters\n",
        "# ----------------------------\n",
        "df_latent = pd.DataFrame(rfm_autoencoded, columns=['Latent 1', 'Latent 2'])\n",
        "df_latent['Cluster'] = clusters\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=df_latent, x='Latent 1', y='Latent 2', hue='Cluster', palette='Set1', s=70)\n",
        "plt.title('Clusters Clients avec Autoencoder + KMeans (k=3)')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# 8. Analyse des segments\n",
        "# ----------------------------\n",
        "cluster_profiles = rfm_df.groupby('Cluster')[['Recency', 'Frequency', 'Monetary']].mean()\n",
        "print(\"\\nProfil des segments clients :\")\n",
        "print(cluster_profiles)\n"
      ],
      "metadata": {
        "id": "nqBlru70CAYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moyennes par cluster\n",
        "cluster_summary = rfm_df.groupby('Cluster').agg({\n",
        "    'Recency': 'mean',\n",
        "    'Frequency': 'mean',\n",
        "    'Monetary': 'mean'\n",
        "}).sort_index()\n",
        "\n",
        "print(cluster_summary)"
      ],
      "metadata": {
        "id": "ur4i2DQeFdQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segment_labels = {\n",
        "    0: 'Inactifs / perdus',\n",
        "    1: 'Occasionnels',\n",
        "    2: 'VIP / fidèles'\n",
        "}\n",
        "\n",
        "rfm_df['Segment_Label'] = rfm_df['Cluster'].map(segment_labels)\n"
      ],
      "metadata": {
        "id": "N8_z2tuYFqi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the number of clients per segment\n",
        "segment_counts = rfm_df['Segment_Label'].value_counts()\n",
        "\n",
        "# Display as a table\n",
        "print(segment_counts)\n",
        "\n",
        "# Display as a chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(data=rfm_df, x='Segment_Label', order=segment_counts.index, palette='Set2')\n",
        "plt.title('Distribution of Customers by Segment')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.xlabel('Segment')\n",
        "plt.xticks(rotation=20)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1jvuuRopFrig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imbalanced-learn\n"
      ],
      "metadata": {
        "id": "X9YwjLw2F4_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Select features and labels\n",
        "X = rfm_df[['Recency', 'Frequency', 'Monetary']]  # Replace this with your actual features\n",
        "y = rfm_df['Cluster']  # The 'Cluster' column contains the cluster labels\n",
        "\n",
        "# Split the data into train and test sets (optional, for validation if needed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the classes in the training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check class distribution before and after SMOTE\n",
        "print(\"Class distribution before SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(pd.Series(y_res).value_counts())\n",
        "\n",
        "# Optional: Visualization to check the balance\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=y_res, palette='Set2')\n",
        "plt.title('Class Distribution After SMOTE')\n",
        "plt.xlabel('Cluster')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.xticks(rotation=20)\n",
        "plt.grid(axis='y')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RIa6K_NzF7m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Normalisation des données\n",
        "scaler = StandardScaler()\n",
        "X = rfm_df[['Recency', 'Frequency', 'Monetary']]  # Features\n",
        "y = rfm_df['Cluster']  # Labels (clusters)\n",
        "\n",
        "# Diviser en jeux d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Appliquer SMOTE pour équilibrer les classes dans le jeu d'entraînement\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Vérification de la répartition après SMOTE\n",
        "print(\"Répartition après SMOTE :\")\n",
        "print(pd.Series(y_train_res).value_counts())\n"
      ],
      "metadata": {
        "id": "9KyFnaESF-sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialiser et entraîner le modèle KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Prédictions sur le jeu de test\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "print(\"Classification Report - KNN :\")\n",
        "print(classification_report(y_test, y_pred_knn))\n"
      ],
      "metadata": {
        "id": "0I-83wGfGPdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialiser et entraîner le modèle Decision Tree\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Prédictions sur le jeu de test\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "print(\"Classification Report - Decision Tree :\")\n",
        "print(classification_report(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "id": "c3DPBGiMnmz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialisation du modèle\n",
        "model = Sequential()\n",
        "\n",
        "# Ajouter une couche d'entrée (la première couche du réseau) et une couche cachée\n",
        "model.add(Dense(units=64, activation='relu', input_dim=X_train_res.shape[1]))  # input_dim correspond au nombre de features dans tes données d'entrée\n",
        "\n",
        "# Ajouter une couche cachée supplémentaire (si nécessaire)\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Ajouter une couche de sortie (taille de sortie dépend du nombre de classes)\n",
        "model.add(Dense(units=1, activation='sigmoid'))  # Pour une classification binaire\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Utiliser 'categorical_crossentropy' pour une classification multiclasse\n",
        "\n",
        "# Entraîner le modèle\n",
        "model.fit(X_train_res, y_train_res, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Faire des prédictions\n",
        "y_pred_ann = model.predict(X_test)\n",
        "\n",
        "# Convertir les prédictions en labels binaires\n",
        "y_pred_ann = (y_pred_ann > 0.5)\n",
        "\n",
        "# Évaluer le modèle\n",
        "print(\"Classification Report - Artificial Neural Network :\")\n",
        "print(classification_report(y_test, y_pred_ann))\n"
      ],
      "metadata": {
        "id": "W21BM8VeHkD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost\n"
      ],
      "metadata": {
        "id": "eqtifIUuyydu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialiser et entraîner le modèle XGBoost\n",
        "xgb = XGBClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "xgb.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Prédictions sur le jeu de test\n",
        "y_pred_xgb = xgb.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "print(\"Classification Report - XGBoost :\")\n",
        "print(classification_report(y_test, y_pred_xgb))\n"
      ],
      "metadata": {
        "id": "HY-elH3kyzog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Accuracy: \", train_accuracy)\n",
        "print(\"Test Accuracy: \", test_accuracy)"
      ],
      "metadata": {
        "id": "QJJtfw4DzNdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade scikit-learn xgboost\n"
      ],
      "metadata": {
        "id": "NdqxTwftz3Qv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall scikit-learn xgboost\n",
        "!pip install scikit-learn xgboost"
      ],
      "metadata": {
        "id": "kjU7BYcX0qZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Définir les hyperparamètres à tester\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],  # Nombre d'arbres\n",
        "    'max_depth': [3, 5, 10],          # Profondeur des arbres\n",
        "    'learning_rate': [0.01, 0.05, 0.1],  # Taux d'apprentissage\n",
        "    'subsample': [0.8, 1.0],          # Fraction d'échantillons pour chaque arbre\n",
        "    'colsample_bytree': [0.8, 1.0],   # Fraction de caractéristiques pour chaque arbre\n",
        "}\n",
        "\n",
        "# Initialiser le modèle XGBoost\n",
        "xgb = XGBClassifier(random_state=42)\n",
        "\n",
        "# Initialiser GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid,\n",
        "                           cv=3, verbose=1, n_jobs=-1, scoring='accuracy')\n",
        "\n",
        "# Exécuter GridSearchCV\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Afficher les meilleurs paramètres trouvés\n",
        "print(\"Best Parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Obtenir le meilleur modèle\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "# Prédictions avec le meilleur modèle\n",
        "y_pred_xgb_best = best_xgb_model.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"Classification Report - Best XGBoost Model:\")\n",
        "print(classification_report(y_test, y_pred_xgb_best))\n"
      ],
      "metadata": {
        "id": "fNWbhmyKzq6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialiser et entraîner le modèle Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Prédictions sur le jeu de test\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "print(\"Classification Report - Random Forest :\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "mfmRLDjAGYFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Prédictions sur l'ensemble d'entraînement\n",
        "y_train_pred_rf = rf.predict(X_train_res)\n",
        "\n",
        "# Calcul des précisions\n",
        "train_accuracy = accuracy_score(y_train_res, y_train_pred_rf)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Train Accuracy : {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy  : {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "oHOKRf5pqjq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Définir les hyperparamètres à tester\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],      # Nombre d'arbres\n",
        "    'max_depth': [10, 20, None],          # Profondeur maximale des arbres\n",
        "    'max_features': ['auto', 'sqrt'],     # Nombre de features à considérer à chaque split\n",
        "    'min_samples_split': [2, 5, 10],      # Nombre minimum d'échantillons pour splitter un noeud\n",
        "    'min_samples_leaf': [1, 2, 4],        # Nombre minimum d'échantillons dans un feuille\n",
        "    'bootstrap': [True, False]            # Utiliser bootstrap pour la création des arbres\n",
        "}\n",
        "\n",
        "# Initialiser le modèle Random Forest\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Initialiser GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
        "                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "# Entraîner le modèle avec GridSearchCV\n",
        "grid_search.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Afficher les meilleurs paramètres trouvés\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Utiliser le meilleur modèle pour faire des prédictions\n",
        "best_rf = grid_search.best_estimator_\n",
        "y_pred_rf = best_rf.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle\n",
        "print(\"Classification Report - Best Random Forest :\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "mg8wq29rrINe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialiser le modèle Random Forest avec les meilleurs paramètres\n",
        "rf = RandomForestClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=10,\n",
        "    bootstrap=True,\n",
        "    max_features='sqrt',\n",
        "    min_samples_leaf=2,\n",
        "    min_samples_split=10,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Entraîner le modèle avec les données d'entraînement\n",
        "rf.fit(X_train_res, y_train_res)\n",
        "\n",
        "# Prédictions sur le jeu de test\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "# Évaluation du modèle : afficher le rapport de classification\n",
        "print(\"Classification Report - Best Random Forest :\")\n",
        "print(classification_report(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "id": "GqlhEsiQsCu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Prédictions sur l'ensemble d'entraînement\n",
        "y_train_pred_rf = rf.predict(X_train_res)\n",
        "\n",
        "# Calcul des précisions\n",
        "train_accuracy = accuracy_score(y_train_res, y_train_pred_rf)\n",
        "test_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "print(f\"Train Accuracy : {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy  : {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "tOl6SgOqwVqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Matrice de confusion\n",
        "cm = confusion_matrix(y_test, y_pred_rf)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix - Random Forest\")\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "EUM3R_QKo3_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LIME (Local Interpretable Model-agnostic Explanations)"
      ],
      "metadata": {
        "id": "LGSpwXZLr8my"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lime\n"
      ],
      "metadata": {
        "id": "4fGw36L5r-C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer  # Import LimeTabularExplainer\n",
        "\n",
        "# 3. Créer un explicateur LIME pour les données tabulaires\n",
        "explainer = LimeTabularExplainer(\n",
        "    training_data=X_train.values,\n",
        "    mode=\"classification\",\n",
        "    training_labels=y_train.values,\n",
        "    feature_names=X.columns,\n",
        "    class_names=np.unique(y_train),\n",
        "    discretize_continuous=True\n",
        ")\n",
        "\n",
        "# 4. Choisir un échantillon pour lequel nous voulons expliquer la prédiction\n",
        "idx = 10  # Par exemple, on choisit la 10e observation du jeu de test\n",
        "data_point = X_test.iloc[idx]\n",
        "\n",
        "# 5. Expliquer la prédiction pour cet échantillon\n",
        "explanation = explainer.explain_instance(data_point.values, rf.predict_proba, num_features=3)\n",
        "\n",
        "# 6. Visualiser l'explication\n",
        "explanation.show_in_notebook(show_table=True, show_all=False)\n",
        "\n",
        "# 7. (Optionnel) Imprimer les résultats de la prédiction pour ce point\n",
        "print(f\"Prediction: {rf.predict([data_point])[0]}\")\n",
        "print(f\"True label: {y_test.iloc[idx]}\")\n",
        "\n",
        "# 8. Évaluation du modèle\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "k2IKt3clvjzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}